{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from operator import itemgetter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.indexes import SQLRecordManager\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import format_document\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "CONNECTION_STRING = (\n",
    "    f\"postgresql+psycopg2://admin:admin@localhost:5433/postgres\"\n",
    ")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=\"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\")\n",
    "COLLECTION_NAME = \"vectordb\"\n",
    "store = PGVector(\n",
    "    collection_name=\"vectordb\",\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "retriever = store.as_retriever()\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# Define the templates\n",
    "condense_question_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(condense_question_template)\n",
    "\n",
    "answer_template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(answer_template)\n",
    "\n",
    "# Function to format the chat history\n",
    "def _format_chat_history(chat_history):\n",
    "    return \"\\n\".join(f\"Human: {human}\\nAssistant: {assistant}\" for human, assistant in chat_history)\n",
    "\n",
    "\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "# Chain for creating standalone question\n",
    "_inputs = RunnableParallel(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "    )\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | model\n",
    "    | StrOutputParser(),\n",
    ")\n",
    "\n",
    "# Chain for retrieving documents and generating the answer\n",
    "_context = {\n",
    "    \"context\": itemgetter(\"standalone_question\") | retriever | _combine_documents,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "conversational_qa_chain = _inputs | _context | ANSWER_PROMPT | ChatOpenAI() | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There is no information provided about where Harrison worked.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"where did harrison work?\",\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
