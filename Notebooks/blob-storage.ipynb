{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "folder_path = \"./hotels\"\n",
    "conn_str='DefaultEndpointsProtocol=https;AccountName=myaccount12345888;AccountKey=Y74KjUF/X085nkGMk0UvliB3ZyUyvGqTemSLn4uMgz8RKV+FupZkFHSfa25CfQTazEGCoB2wFyNE+AStysJj2g==;EndpointSuffix=core.windows.net'\n",
    "\n",
    "container_name = \"hotelcontainer\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(conn_str=conn_str)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Instantiate a new BlobServiceClient using a connection string\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if os.path.isfile(os.path.join(folder_path, filename)):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=filename)\n",
    "\n",
    "        with open(file_path, \"rb\") as data:\n",
    "            blob_client.upload_blob(data, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can link ACS BlobStorage and the ACS VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AzureBlobStorageContainerLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = AzureBlobStorageContainerLoader(conn_str=conn_str, container=container_name)\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings: OpenAIEmbeddings = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\", chunk_size=1)\n",
    "index_name: str = \"langchain-vector-demo\"\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=os.environ.get(\"SEARCH_ENDPOINT\"),\n",
    "    azure_search_key=os.environ.get(\"SEARCH_API_KEY\"),\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vector_store.add_documents(documents=docs)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run that code multiple times, we would add the same documents again and again - quick solution is to create the complete index again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "\n",
    "index_name = \"langchain-vector-demo\"\n",
    "endpoint = os.environ[\"SEARCH_ENDPOINT\"]\n",
    "api_key = os.environ[\"SEARCH_API_KEY\"]\n",
    "\n",
    "credential = AzureKeyCredential(api_key)\n",
    "client = SearchClient(endpoint=endpoint,\n",
    "                      index_name=index_name,\n",
    "                      credential=credential)\n",
    "\n",
    "results = client.search(search_text=\"*\")\n",
    "documents = [result for result in results]\n",
    "\n",
    "print(len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'langchain-vector-demo' has been deleted.\n"
     ]
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "import os\n",
    "\n",
    "index_client = SearchIndexClient(endpoint, AzureKeyCredential(api_key))\n",
    "index_client.delete_index(index_name)\n",
    "\n",
    "print(f\"Index '{index_name}' has been deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we could create the Index again - but it would be actually better to:\n",
    "\n",
    "1. Not have duplicated documents in the vectorstore\n",
    "2. Not to drop Indexes and recreate them everything a source document changes\n",
    "\n",
    "For this issue, the indexing API was developed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
